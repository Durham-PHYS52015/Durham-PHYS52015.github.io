---
title: "Task parallelism"
weight: 5
draft: true
---

# OpenMP task parallelism

## Motivation and examples

Suppose that we wish to parallelise some algorithm where the amount of
work is not easily determined up front.

This is the case for many graph algorithms. For example breadth first
search through a graph starts from a single point but creates
independent work whenever a search step creates more than one new
vertex.

Even seemingly regular computations, such as computing the [Cholesky
factorisation](https://en.wikipedia.org/wiki/Cholesky_decomposition)
of a matrix, have a lot of potentially parallel tasks.

{{< manfig
    src="cholesky-decomp-magma.png"
    width="75%"
    caption="Separated (left) and fused (right) task graphs for computation of a Cholesky factorisation. Reproduced from [a presentation](https://icl.utk.edu/projectsfiles/magma/tutorial/ecp2018-magma-tutorial.pdf) on [MAGMA](https://icl.utk.edu/magma/)."
    >}}

Tasks may also be an appropriate parallelisation approach when we have
quite dynamic datastructures. In many scientific simulations, the
amount of resolution we need to see interesting detail may change
during the course of the simulation. Think about simulating a wave
moving across an otherwise flat pond. Far away from the wave, we can
describe the shape of the pond accurately with only a coarse
representation. Near the wave, if we want the shape to be accurate, we
need a lot of detail. 
One way to capture this is to adaptively change the resolution in
response to the dynamic properties of the simulation. 

For example, the video below shows a simulation
of a [Kelvin-Helmholtz
instability](https://en.wikipedia.org/wiki/Kelvinâ€“Helmholtz_instability),
the resolution is adaptive around the two fronts. This example is
generated by [SWIFT](http://swift.dur.ac.uk/) which is developed at
the [ICC](http://www.icc.dur.ac.uk) here in Durham.

{{< youtube "sce-AWTbXFI" >}}

Or a lock-exchange example, where the mesh (and resolution is also
shown). This time from [Fluidity](https://fluidityproject.github.io).

{{< youtube "twQEWwYCaNI" >}}

## Challenges

In comparison with the loop parallelism we've already seen, the
implementation of task based parallelism is somewhat more complicated.

Let's think about what we need.

1. We need a way of expression that certain bits of code constitute a
   task: something that should be performed by a single thread.
2. We need a way of expressing _dependencies_ between tasks. That is
   "task A" needs the result of "task B".
We need a way of expressing that certain bits of code constitute a
task: something that should be performed by a single thread to
produce a result.

We also need the ability to 
